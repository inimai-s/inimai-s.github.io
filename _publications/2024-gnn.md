---
title: "Intelligent knowledge base search tool using large language model and graph neural network"
collection: publications
category: manuscripts
permalink: /publication/2024-gnn
excerpt: ''
date: 2024-06-07
isconf: true
venue: 'SPIE'
fullvenue: 'SPIE Defense + Commercial Sensing 2024'
special: 'as an <strong>Invited Paper and Oral Presentation</strong>
selected: true
paperurl: 'https://doi.org/10.1117/12.3014075'
authors: 'Kevin Payumo, <strong>Inimai Subramanian</strong>, Thomas Lu, Edward Chow'
citation: 'Kevin Payumo, <strong>Inimai Subramanian</strong>, Thomas Lu, and Edward Chow "Intelligent knowledge base search tool using large language model and graph neural network", Proc. SPIE 13040, Pattern Recognition and Prediction XXXV, 1304007 (7 June 2024); https://doi.org/10.1117/12.3014075'
---

Within many organizations, a vast number of communications, memos, reports and documents have been accumulated in internal servers. Efficiently discovering relevant entries can reduce time spent addressing organizational needs such as personnel skills matching or anomaly resolution. However, per organization, information retrieval on these disparate data types can be challenging, as systems must be designed for their domain while accounting for unstructured and inconsistent datasets. Traditional querying via search terms often requires relevancy tuning by subject matter experts which makes it difficult to build retrieval systems. We argue that development of retrieval systems can be simplified and enhanced by embedding data with Large Language Models (LLMs), organizing information in a Knowledge Graph (KG) structure, and further encoding their relational features through a Graph Neural Network (GNN). One of the major challenges of using GNNs for information retrieval is optimizing negative edge selection. Training GNNs requires a balanced ratio between positive and negative edges however the space of negative edges is exponentially larger than positive edges. In this work, we extend the LLM-GNN hybrid architecture by applying ensemble voting on a set of trained LLM-GNNs. Preliminary results have shown modest improvement on our personnel-document matching tasks. This work contributes to a developmental effort that aims to help engineers and scientists find new research opportunities, learn from past mistakes, and quickly address future needs.